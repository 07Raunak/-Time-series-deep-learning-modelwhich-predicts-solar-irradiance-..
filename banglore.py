# -*- coding: utf-8 -*-
"""Banglore.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12LPRdRIfw63_o156m84a2dSMuwXUOJtP
"""

import matplotlib.pyplot as plt
import numpy as np

# Define the metrics for each model
metrics = ["RMSE", "MSE", "MAE", "R2", "MAPE"]

# Define the average metrics for each model
average_metrics = {
    "LSTM": [29.10, 846.60, 16.21, 0.99, 7.92],
    "BiLSTM": [29.23, 854.53, 16.16, 0.99, 7.97],
    "GRU": [29.41, 865.28, 17.00, 0.99, 8.67],
    "CNN": [364.95, 133191.96, 277.73, -0.58, 146.83],
    "RNN": [28.93, 836.85, 16.09, 0.99, 8.14],
    "Hybrid": [28.70, 824.00, 15.55, 0.99, 7.88]
}

# Define traditional models
traditional_models = ["LSTM", "BiLSTM", "GRU", "CNN", "RNN"]

# Create subplots for each comparison
fig, axes = plt.subplots(nrows=len(traditional_models), ncols=1, figsize=(10, 30))
axes = axes.flatten()

for i, traditional_model in enumerate(traditional_models):
    hybrid_model = "Hybrid"

    # Extract metrics for traditional and hybrid models
    traditional_metrics = average_metrics[traditional_model]
    hybrid_metrics = average_metrics[hybrid_model]

    # Define the bar positions
    bar_width = 0.35
    bar_positions = np.arange(len(metrics))

    # Plot the bar charts
    axes[i].bar(bar_positions - bar_width/2, traditional_metrics, bar_width, label=traditional_model, color='blue')
    axes[i].bar(bar_positions + bar_width/2, hybrid_metrics, bar_width, label=hybrid_model, color='red')

    # Set the chart title and labels
    axes[i].set_title(f'{traditional_model} vs {hybrid_model}')
    axes[i].set_xlabel('Metrics')
    axes[i].set_ylabel('Values')
    axes[i].set_xticks(bar_positions)
    axes[i].set_xticklabels(metrics)
    axes[i].legend()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Assuming y_test_inv contains the actual test values from your previous code
actual_values = y_test_inv.flatten().tolist()

# Define the original models and hybrid models
original_models = ["LSTM", "GRU", "CNN", "RNN", "BiLSTM"]
hybrid_models = ["Hybrid_LSTM_RNN", "Hybrid_RNN_GRU"]

# Creating a dictionary for best predictions
best_test_predictions = {}
for model_name in original_models + hybrid_models:
    best_iteration = min_iteration_metrics["RMSE"]["iteration"] - 1  # Subtract 1 because iterations are 1-based in printout
    best_test_predictions[model_name] = y_pred_list[best_iteration].flatten().tolist()

# Define average metrics for each model
average_metrics = {
    "LSTM": [29.10, 846.60, 16.21, 0.99, 7.92],
    "BiLSTM": [29.23, 854.53, 16.16, 0.99, 7.97],
    "GRU": [29.41, 865.28, 17.00, 0.99, 8.67],
    "CNN": [364.95, 133191.96, 277.73, -0.58, 146.83],
    "RNN": [28.93, 836.85, 16.09, 0.99, 8.14],
    "Hybrid": [28.70, 824.00, 15.55, 0.99, 7.88]
}

# Metrics to be compared
metrics = ["RMSE", "MSE", "MAE", "R2", "MAPE"]

# Create a figure with subplots for time series and bar plots
fig, axes = plt.subplots(nrows=len(original_models), ncols=len(hybrid_models) + 1, figsize=(25, 20))
axes = axes.flatten()

# Plotting time series predictions
for i, original_model in enumerate(original_models):
    for j, hybrid_model in enumerate(hybrid_models):
        ax = axes[i * (len(hybrid_models) + 1) + j]
        original_pred = best_test_predictions[original_model]
        hybrid_pred = best_test_predictions[hybrid_model]

        ax.plot(actual_values, label='Actual', color='b')
        ax.plot(original_pred, label=f'Best {original_model}', color='r')
        ax.plot(hybrid_pred, label=f'Best {hybrid_model}', color='g')
        ax.set_title(f'{original_model} vs {hybrid_model}: Actual vs Best Predicted')
        ax.set_xlabel('Time')
        ax.set_ylabel('Predicted Values')
        ax.legend(loc='upper left')

# Plotting average metrics comparison
for i, original_model in enumerate(original_models):
    ax = axes[i * (len(hybrid_models) + 1) + len(hybrid_models)]
    bar_width = 0.35
    bar_positions = np.arange(len(metrics))

    original_metrics = average_metrics[original_model]
    hybrid_metrics = average_metrics["Hybrid"]

    ax.bar(bar_positions - bar_width/2, original_metrics, bar_width, label=original_model, color='blue')
    ax.bar(bar_positions + bar_width/2, hybrid_metrics, bar_width, label='Hybrid', color='green')
    ax.set_title(f'{original_model} vs Hybrid: Average Metrics')
    ax.set_xlabel('Metrics')
    ax.set_ylabel('Values')
    ax.set_xticks(bar_positions)
    ax.set_xticklabels(metrics)
    ax.legend()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Example initialization of y_test_inv, replace this with your actual data
y_test_inv = np.random.rand(100)  # Assuming 100 data points as an example

# Define the original models and hybrid models
original_models = ["LSTM", "GRU", "CNN", "RNN", "BiLSTM"]
hybrid_models = ["Hybrid_LSTM_RNN", "Hybrid_RNN_GRU"]

# Creating a dictionary for best predictions
best_test_predictions = {}
for model_name in original_models + hybrid_models:
    best_iteration = min_iteration_metrics["RMSE"]["iteration"] - 1  # Subtract 1 because iterations are 1-based in printout
    best_test_predictions[model_name] = y_pred_list[best_iteration].flatten().tolist()

# Define average metrics for each model
average_metrics = {
    "LSTM": [29.10, 846.60, 16.21, 0.99, 7.92],
    "BiLSTM": [29.23, 854.53, 16.16, 0.99, 7.97],
    "GRU": [29.41, 865.28, 17.00, 0.99, 8.67],
    "CNN": [364.95, 133191.96, 277.73, -0.58, 146.83],
    "RNN": [28.93, 836.85, 16.09, 0.99, 8.14],
    "Hybrid": [28.70, 824.00, 15.55, 0.99, 7.88]
}

# Metrics to be compared
metrics = ["RMSE", "MSE", "MAE", "R2", "MAPE"]

# Actual values flattened and converted to a list
actual_values = y_test_inv.flatten().tolist()

# Create a figure with subplots for time series and bar plots
fig, axes = plt.subplots(nrows=len(original_models), ncols=len(hybrid_models) + 1, figsize=(25, 20))
axes = axes.flatten()

# Plotting time series predictions
for i, original_model in enumerate(original_models):
    for j, hybrid_model in enumerate(hybrid_models):
        ax = axes[i * (len(hybrid_models) + 1) + j]
        original_pred = best_test_predictions[original_model]
        hybrid_pred = best_test_predictions[hybrid_model]

        ax.plot(actual_values, label='Actual', color='b')
        ax.plot(original_pred, label=f'Best {original_model}', color='r')
        ax.plot(hybrid_pred, label=f'Best {hybrid_model}', color='g')
        ax.set_title(f'{original_model} vs {hybrid_model}: Actual vs Best Predicted')
        ax.set_xlabel('Time')
        ax.set_ylabel('Predicted Values')
        ax.legend(loc='upper left')

# Plotting average metrics comparison
for i, original_model in enumerate(original_models):
    ax = axes[i * (len(hybrid_models) + 1) + len(hybrid_models)]
    bar_width = 0.35
    bar_positions = np.arange(len(metrics))

    original_metrics = average_metrics[original_model]
    hybrid_metrics = average_metrics["Hybrid"]

    ax.bar(bar_positions - bar_width/2, original_metrics, bar_width, label=original_model, color='blue')
    ax.bar(bar_positions + bar_width/2, hybrid_metrics, bar_width, label='Hybrid', color='green')
    ax.set_title(f'{original_model} vs Hybrid: Average Metrics')
    ax.set_xlabel('Metrics')
    ax.set_ylabel('Values')
    ax.set_xticks(bar_positions)
    ax.set_xticklabels(metrics)
    ax.legend()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Example initialization of y_test_inv, replace this with your actual data
y_test_inv = np.random.rand(100)  # Assuming 100 data points as an example

# Example initialization of min_iteration_metrics, replace this with your actual data
min_iteration_metrics = {
    "RMSE": {"iteration": 5}
}

# Example initialization of y_pred_list, replace this with your actual data
y_pred_list = [np.random.rand(100) for _ in range(10)]  # Assuming 10 iterations with 100 data points each

# Define the original models and hybrid models
original_models = ["LSTM", "GRU", "CNN", "RNN", "BiLSTM"]
hybrid_models = ["Hybrid_LSTM_RNN"]

# Creating a dictionary for best predictions
best_test_predictions = {}
for model_name in original_models + hybrid_models:
    best_iteration = min_iteration_metrics["RMSE"]["iteration"] - 1  # Subtract 1 because iterations are 1-based in printout
    best_test_predictions[model_name] = y_pred_list[best_iteration].flatten().tolist()

# Define average metrics for each model
average_metrics = {
    "LSTM": [29.10, 846.60, 16.21, 0.99, 7.92],
    "BiLSTM": [29.23, 854.53, 16.16, 0.99, 7.97],
    "GRU": [29.41, 865.28, 17.00, 0.99, 8.67],
    "CNN": [364.95, 133191.96, 277.73, -0.58, 146.83],
    "RNN": [28.93, 836.85, 16.09, 0.99, 8.14],
    "Hybrid": [28.70, 824.00, 15.55, 0.99, 7.88]
}

# Metrics to be compared
metrics = ["RMSE", "MSE", "MAE", "R2", "MAPE"]

# Actual values flattened and converted to a list
actual_values = y_test_inv.flatten().tolist()

# Create a figure with subplots for time series and bar plots
fig, axes = plt.subplots(nrows=len(original_models), ncols=len(hybrid_models) + 1, figsize=(25, 20))
axes = axes.flatten()

# Plotting time series predictions
for i, original_model in enumerate(original_models):
    for j, hybrid_model in enumerate(hybrid_models):
        ax = axes[i * (len(hybrid_models) + 1) + j]
        original_pred = best_test_predictions[original_model]
        hybrid_pred = best_test_predictions[hybrid_model]

        ax.plot(actual_values, label='Actual', color='b')
        ax.plot(original_pred, label=f'Best {original_model}', color='r')
        ax.plot(hybrid_pred, label=f'Best {hybrid_model}', color='g')
        ax.set_title(f'{original_model} vs {hybrid_model}: Actual vs Best Predicted')
        ax.set_xlabel('Time')
        ax.set_ylabel('Predicted Values')
        ax.legend(loc='upper left')

# Plotting average metrics comparison
for i, original_model in enumerate(original_models):
    ax = axes[i * (len(hybrid_models) + 1) + len(hybrid_models)]
    bar_width = 0.35
    bar_positions = np.arange(len(metrics))

    original_metrics = average_metrics[original_model]
    hybrid_metrics = average_metrics["Hybrid"]

    ax.bar(bar_positions - bar_width/2, original_metrics, bar_width, label=original_model, color='blue')
    ax.bar(bar_positions + bar_width/2, hybrid_metrics, bar_width, label='Hybrid', color='green')
    ax.set_title(f'{original_model} vs Hybrid: Average Metrics')
    ax.set_xlabel('Metrics')
    ax.set_ylabel('Values')
    ax.set_xticks(bar_positions)
    ax.set_xticklabels(metrics)
    ax.legend()

plt.tight_layout()
plt.show()

Average metrics for LSTM:
Average RMSE: 29.10
Average MSE: 846.60
Average MAE: 16.21
Average R2: 0.99
Average MAPE: 7.92

Average metrics for BiLSTM:
Average RMSE: 29.23
Average MSE: 854.53
Average MAE: 16.16
Average R2: 0.99
Average MAPE: 7.97

Average metrics for GRU:
Average RMSE: 29.41
Average MSE: 865.28
Average MAE: 17.00
Average R2: 0.99
Average MAPE: 8.67

Average metrics for CNN:
Average RMSE: 364.95
Average MSE: 133191.96
Average MAE: 277.73
Average R2: -0.58
Average MAPE: 146.83

Average metrics for RNN:
Average RMSE: 28.93
Average MSE: 836.85
Average MAE: 16.09
Average R2: 0.99
Average MAPE: 8.14

Average metrics for hybrid:
Average RMSE: 28.70
Average MSE: 824.00
Average MAE: 15.55
Average R2: 0.99
Average MAPE: 7.88



import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# # Define the original and hybrid models
# original_models = ["LSTM", "GRU", "CNN", "RNN", "BiLSTM"]
# hybrid_models = ["Hybrid_LSTM_RNN"]
# all_models = original_models + hybrid_models

# # Prepare the data for the box plots
# metrics = ["RMSE", "MSE", "MAE", "R2"]

# # Create a DataFrame for each metric
# data_frames = {metric: pd.DataFrame(columns=all_models) for metric in metrics}

# for model_name in all_models:
#     for metric in metrics:
#         data_frames[metric][model_name] = results[model_name][metric]

# # Create a larger figure with subplots for each metric
# fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))
# axes = axes.flatten()

# for idx, metric in enumerate(metrics):
#     sns.boxplot(data=data_frames[metric], ax=axes[idx], width=0.7)
#     axes[idx].set_title(f'Box Plot of {metric} Across Models', fontsize=14)
#     axes[idx].set_xlabel('Model', fontsize=12)
#     axes[idx].set_ylabel(metric, fontsize=12)
#     axes[idx].tick_params(axis='x', labelrotation=45)

# plt.tight_layout(pad=3.0)
# plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Define the original and hybrid models
original_models = ["LSTM", "GRU", "CNN", "RNN", "BiLSTM"]
hybrid_models = ["Hybrid_LSTM_RNN"]
all_models = original_models + hybrid_models

# Define the average metrics based on the provided data
results = {
    "LSTM": {"RMSE": [31.56], "MSE": [996.12], "MAE": [16.41], "R2": [0.99]},
    "GRU": {"RMSE": [32.00], "MSE": [1024.24], "MAE": [16.82], "R2": [0.99]},
    "CNN": {"RMSE": [346.11], "MSE": [119801.86], "MAE": [260.02], "R2": [-0.72]},
    "RNN": {"RMSE": [32.06], "MSE": [1028.10], "MAE": [16.38], "R2": [0.99]},
    "BiLSTM": {"RMSE": [31.89], "MSE": [1017.36], "MAE": [16.78], "R2": [0.99]},
    "Hybrid_LSTM_RNN": {"RMSE": [32.32], "MSE": [1045.31], "MAE": [16.27], "R2": [0.99]}
}

# Prepare the data for the box plots
metrics = ["RMSE", "MSE", "MAE", "R2"]

# Create a DataFrame for each metric
data_frames = {metric: pd.DataFrame(columns=all_models) for metric in metrics}

for model_name in all_models:
    for metric in metrics:
        data_frames[metric][model_name] = results[model_name][metric]

# Create a larger figure with subplots for each metric
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))
axes = axes.flatten()

for idx, metric in enumerate(metrics):
    sns.boxplot(data=data_frames[metric], ax=axes[idx], width=0.7)
    axes[idx].set_title(f'Box Plot of {metric} Across Models', fontsize=14)
    axes[idx].set_xlabel('Model', fontsize=12)
    axes[idx].set_ylabel(metric, fontsize=12)
    axes[idx].tick_params(axis='x', labelrotation=45)

plt.tight_layout(pad=3.0)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Define the original and hybrid models
original_models = ["LSTM", "GRU", "CNN", "RNN", "BiLSTM"]
hybrid_models = ["Hybrid_LSTM_RNN"]
all_models = original_models + hybrid_models

# Provided average metrics
metrics = {
    "LSTM": {"RMSE": 31.56, "MSE": 996.12, "MAE": 16.41, "R2": 0.99, "MAPE": 8.70},
    "BiLSTM": {"RMSE": 31.89, "MSE": 1017.36, "MAE": 16.78, "R2": 0.99, "MAPE": 8.68},
    "GRU": {"RMSE": 32.00, "MSE": 1024.24, "MAE": 16.82, "R2": 0.99, "MAPE": 8.63},
    "CNN": {"RMSE": 346.11, "MSE": 119801.86, "MAE": 260.02, "R2": -0.72, "MAPE": 131.33},
    "RNN": {"RMSE": 32.06, "MSE": 1028.10, "MAE": 16.38, "R2": 0.99, "MAPE": 8.54},
    "Hybrid_LSTM_RNN": {"RMSE": 32.32, "MSE": 1045.31, "MAE": 16.27, "R2": 0.99, "MAPE": 8.38}
}

# Create DataFrames for each metric
data_frames = {metric: pd.DataFrame(columns=all_models) for metric in metrics["LSTM"].keys()}

for model_name in all_models:
    for metric, values in metrics[model_name].items():
        data_frames[metric].loc[0, model_name] = values

# Create box plots
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))
axes = axes.flatten()

for idx, metric in enumerate(data_frames.keys()):
    sns.boxplot(data=data_frames[metric], ax=axes[idx], width=0.7)
    axes[idx].set_title(f'Box Plot of {metric} Across Models', fontsize=14)
    axes[idx].set_xlabel('Model', fontsize=12)
    axes[idx].set_ylabel(metric, fontsize=12)
    axes[idx].tick_params(axis='x', labelrotation=45)

plt.tight_layout(pad=3.0)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Define the original and hybrid models
original_models = ["LSTM", "BiLSTM", "GRU", "CNN", "RNN"]
hybrid_models = ["Hybrid_LSTM_RNN"]
all_models = original_models + hybrid_models

# Provided average metrics
metrics = {
    "LSTM": {"RMSE": 31.56, "MSE": 996.12, "MAE": 16.41, "R2": 0.99, "MAPE": 8.70},
    "BiLSTM": {"RMSE": 31.89, "MSE": 1017.36, "MAE": 16.78, "R2": 0.99, "MAPE": 8.68},
    "GRU": {"RMSE": 32.00, "MSE": 1024.24, "MAE": 16.82, "R2": 0.99, "MAPE": 8.63},
    "CNN": {"RMSE": 346.11, "MSE": 119801.86, "MAE": 260.02, "R2": -0.72, "MAPE": 131.33},
    "RNN": {"RMSE": 32.06, "MSE": 1028.10, "MAE": 16.38, "R2": 0.99, "MAPE": 8.54},
    "Hybrid_LSTM_RNN": {"RMSE": 32.32, "MSE": 1045.31, "MAE": 16.27, "R2": 0.99, "MAPE": 8.38}
}

# Create DataFrames for each metric
data_frames = {metric: pd.DataFrame(columns=all_models) for metric in metrics["LSTM"].keys()}

for model_name in all_models:
    for metric, values in metrics[model_name].items():
        data_frames[metric].loc[0, model_name] = values

# Create box plots
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 12))
axes = axes.flatten()

for idx, (metric, df) in enumerate(data_frames.items()):
    sns.boxplot(data=df, ax=axes[idx], width=0.7)
    axes[idx].set_title(f'Box Plot of {metric} Across Models', fontsize=14)
    axes[idx].set_xlabel('Model', fontsize=12)
    axes[idx].set_ylabel(metric, fontsize=12)
    axes[idx].tick_params(axis='x', labelrotation=45)

plt.tight_layout(pad=3.0)
plt.show()