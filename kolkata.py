# -*- coding: utf-8 -*-
"""kolkata.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13f5LKk-QcBV177wkWjkfg25b5Hu-x2Dq
"""

Average metrics for LSTM:
Average RMSE: 32.89
Average MSE: 1081.73
Average MAE: 17.15
Average R2: 0.98
Average MAPE: 9.68

Average metrics for BiLSTM:
Average RMSE: 32.75
Average MSE: 1072.53
Average MAE: 16.99
Average R2: 0.98
Average MAPE: 9.42

Average metrics for GRU:
Average RMSE: 32.83
Average MSE: 1078.12
Average MAE: 17.21
Average R2: 0.98
Average MAPE: 9.56

Average metrics for CNN:
Average RMSE: 317.27
Average MSE: 100672.28
Average MAE: 237.99
Average R2: -0.63
Average MAPE: 141.55

Average metrics for RNN:
Average RMSE: 32.98
Average MSE: 1087.71
Average MAE: 17.05
Average R2: 0.98
Average MAPE: 9.43

Average metrics for hybrid:
Average RMSE: 32.43
Average MSE: 1118.15
Average MAE: 16.94
Average R2: 0.98
Average MAPE: 9.01

import matplotlib.pyplot as plt
import numpy as np

# Define the metrics for each model
metrics = ["RMSE", "MSE", "MAE", "R2", "MAPE"]

# Define the average metrics for each model
average_metrics = {
    "LSTM": [32.89, 1081.73, 17.15, 0.98, 9.68],
    "BiLSTM": [32.75, 1072.53, 16.99, 0.98, 9.42],
    "GRU": [32.83, 1078.12, 17.21, 0.98, 9.56],
    "CNN": [317.27, 100672.28, 237.99, -0.63, 141.55],
    "RNN": [32.98, 1087.71, 17.05, 0.98, 9.43],
    "Hybrid": [32.43, 1118.15, 16.94, 0.98, 9.01]
}

# Define traditional models
traditional_models = ["LSTM", "BiLSTM", "GRU", "CNN", "RNN"]

# Create subplots for each comparison
fig, axes = plt.subplots(nrows=len(traditional_models), ncols=1, figsize=(10, 30))
axes = axes.flatten()

for i, traditional_model in enumerate(traditional_models):
    hybrid_model = "Hybrid"

    # Extract metrics for traditional and hybrid models
    traditional_metrics = average_metrics[traditional_model]
    hybrid_metrics = average_metrics[hybrid_model]

    # Define the bar positions
    bar_width = 0.35
    bar_positions = np.arange(len(metrics))

    # Plot the bar charts
    axes[i].bar(bar_positions - bar_width/2, traditional_metrics, bar_width, label=traditional_model, color='blue')
    axes[i].bar(bar_positions + bar_width/2, hybrid_metrics, bar_width, label=hybrid_model, color='red')

    # Set the chart title and labels
    axes[i].set_title(f'{traditional_model} vs {hybrid_model}')
    axes[i].set_xlabel('Metrics')
    axes[i].set_ylabel('Values')
    axes[i].set_xticks(bar_positions)
    axes[i].set_xticklabels(metrics)
    axes[i].legend()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Example initialization of y_test_inv, replace this with your actual data
y_test_inv = np.random.rand(100)  # Assuming 100 data points as an example

# Example initialization of min_iteration_metrics, replace this with your actual data
min_iteration_metrics = {
    "RMSE": {"iteration": 5}
}

# Example initialization of y_pred_list, replace this with your actual data
y_pred_list = [np.random.rand(100) for _ in range(10)]  # Assuming 10 iterations with 100 data points each

# Define the original models and hybrid models
original_models = ["LSTM", "GRU", "CNN", "RNN", "BiLSTM"]
hybrid_models = ["Hybrid"]

# Creating a dictionary for best predictions
best_test_predictions = {}
for model_name in original_models + hybrid_models:
    best_iteration = min_iteration_metrics["RMSE"]["iteration"] - 1  # Subtract 1 because iterations are 1-based in printout
    best_test_predictions[model_name] = y_pred_list[best_iteration].flatten().tolist()

# Define average metrics for each model
average_metrics = {
    "LSTM": [32.89, 1081.73, 17.15, 0.98, 9.68],
    "BiLSTM": [32.75, 1072.53, 16.99, 0.98, 9.42],
    "GRU": [32.83, 1078.12, 17.21, 0.98, 9.56],
    "CNN": [317.27, 100672.28, 237.99, -0.63, 141.55],
    "RNN": [32.98, 1087.71, 17.05, 0.98, 9.43],
    "Hybrid": [32.43, 1118.15, 16.94, 0.98, 9.01]
}

# Metrics to be compared
metrics = ["RMSE", "MSE", "MAE", "R2", "MAPE"]

# Actual values flattened and converted to a list
actual_values = y_test_inv.flatten().tolist()

# Create a figure with subplots for time series and bar plots
fig, axes = plt.subplots(nrows=len(original_models), ncols=len(hybrid_models) + 1, figsize=(25, 20))
axes = axes.flatten()

# Plotting time series predictions
for i, original_model in enumerate(original_models):
    for j, hybrid_model in enumerate(hybrid_models):
        ax = axes[i * (len(hybrid_models) + 1) + j]
        original_pred = best_test_predictions[original_model]
        hybrid_pred = best_test_predictions[hybrid_model]

        ax.plot(actual_values, label='Actual', color='b')
        ax.plot(original_pred, label=f'Best {original_model}', color='r')
        ax.plot(hybrid_pred, label=f'Best {hybrid_model}', color='g')
        ax.set_title(f'{original_model} vs {hybrid_model}: Actual vs Best Predicted')
        ax.set_xlabel('Time')
        ax.set_ylabel('Predicted Values')
        ax.legend(loc='upper left')

# Plotting average metrics comparison
for i, original_model in enumerate(original_models):
    ax = axes[i * (len(hybrid_models) + 1) + len(hybrid_models)]
    bar_width = 0.35
    bar_positions = np.arange(len(metrics))

    original_metrics = average_metrics[original_model]
    hybrid_metrics = average_metrics["Hybrid"]

    ax.bar(bar_positions - bar_width/2, original_metrics, bar_width, label=original_model, color='blue')
    ax.bar(bar_positions + bar_width/2, hybrid_metrics, bar_width, label='Hybrid', color='green')
    ax.set_title(f'{original_model} vs Hybrid: Average Metrics')
    ax.set_xlabel('Metrics')
    ax.set_ylabel('Values')
    ax.set_xticks(bar_positions)
    ax.set_xticklabels(metrics)
    ax.legend()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Define the original and hybrid models
original_models = ["LSTM", "GRU", "CNN", "RNN", "BiLSTM"]
hybrid_models = ["Hybrid"]
all_models = original_models + hybrid_models

# Updated average metrics based on the provided data
results = {
    "LSTM": {"RMSE": [32.89], "MSE": [1081.73], "MAE": [17.15], "R2": [0.98]},
    "GRU": {"RMSE": [32.83], "MSE": [1078.12], "MAE": [17.21], "R2": [0.98]},
    "CNN": {"RMSE": [317.27], "MSE": [100672.28], "MAE": [237.99], "R2": [-0.63]},
    "RNN": {"RMSE": [32.98], "MSE": [1087.71], "MAE": [17.05], "R2": [0.98]},
    "BiLSTM": {"RMSE": [32.75], "MSE": [1072.53], "MAE": [16.99], "R2": [0.98]},
    "Hybrid": {"RMSE": [32.43], "MSE": [1118.15], "MAE": [16.94], "R2": [0.98]}
}

# Prepare the data for the box plots
metrics = ["RMSE", "MSE", "MAE", "R2"]

# Create a DataFrame for each metric
data_frames = {metric: pd.DataFrame(columns=all_models) for metric in metrics}

for model_name in all_models:
    for metric in metrics:
        data_frames[metric][model_name] = results[model_name][metric]

# Create a larger figure with subplots for each metric
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))
axes = axes.flatten()

for idx, metric in enumerate(metrics):
    sns.boxplot(data=data_frames[metric], ax=axes[idx], width=0.7)
    axes[idx].set_title(f'Box Plot of {metric} Across Models', fontsize=14)
    axes[idx].set_xlabel('Model', fontsize=12)
    axes[idx].set_ylabel(metric, fontsize=12)
    axes[idx].tick_params(axis='x', labelrotation=45)

plt.tight_layout(pad=3.0)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Updated average metrics
average_metrics = {
    "LSTM": {"RMSE": 32.89, "MSE": 1081.73, "MAE": 17.15, "R2": 0.98, "MAPE": 9.68},
    "BiLSTM": {"RMSE": 32.75, "MSE": 1072.53, "MAE": 16.99, "R2": 0.98, "MAPE": 9.42},
    "GRU": {"RMSE": 32.83, "MSE": 1078.12, "MAE": 17.21, "R2": 0.98, "MAPE": 9.56},
    "RNN": {"RMSE": 32.98, "MSE": 1087.71, "MAE": 17.05, "R2": 0.98, "MAPE": 9.43},
    "Hybrid": {"RMSE": 32.43, "MSE": 1118.15, "MAE": 16.94, "R2": 0.98, "MAPE": 9.01}
}

# Prepare data for box plot
metrics_list = []

# Iterate over models and prepare the list
for model_name, metrics in average_metrics.items():
    metrics_list.append({
        "Model": model_name,
        "RMSE": metrics["RMSE"],
        "MAE": metrics["MAE"],
        "MSE": metrics["MSE"],
        "R2": metrics["R2"],
        "MAPE": metrics["MAPE"]
    })

# Create DataFrame
metrics_df = pd.DataFrame(metrics_list)

# Convert 'Model' column to categorical type for better plot ordering
metrics_df["Model"] = pd.Categorical(metrics_df["Model"], categories=metrics_df["Model"].unique())

# Plot box plots for each metric
fig, axes = plt.subplots(3, 2, figsize=(15, 18))
fig.suptitle('Box Plots of Model Evaluation Metrics', fontsize=16)

sns.boxplot(x='Model', y='RMSE', data=metrics_df, ax=axes[0, 0])
axes[0, 0].set_title('RMSE', fontsize=14)
axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45, ha='right')

sns.boxplot(x='Model', y='MAE', data=metrics_df, ax=axes[0, 1])
axes[0, 1].set_title('MAE', fontsize=14)
axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45, ha='right')

sns.boxplot(x='Model', y='MSE', data=metrics_df, ax=axes[1, 0])
axes[1, 0].set_title('MSE', fontsize=14)
axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45, ha='right')

sns.boxplot(x='Model', y='R2', data=metrics_df, ax=axes[1, 1])
axes[1, 1].set_title('R2', fontsize=14)
axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45, ha='right')

sns.boxplot(x='Model', y='MAPE', data=metrics_df, ax=axes[2, 0])
axes[2, 0].set_title('MAPE', fontsize=14)
axes[2, 0].set_xticklabels(axes[2, 0].get_xticklabels(), rotation=45, ha='right')

# Hide the last subplot (bottom right) since it's not used
fig.delaxes(axes[2, 1])

# Adjust layout and show plot
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()